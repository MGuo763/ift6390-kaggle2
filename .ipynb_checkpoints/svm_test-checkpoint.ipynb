{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976c2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tokenizer and lemmatizer\n",
    "import nltk\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fe089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\guomu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\guomu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\guomu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If nltk does not already include those packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1258f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change text like \"Ohhhhhh my gosh!!!!!!!!\" to \"Ohhh my gosh!!!\"\n",
    "def remove_repetitions(text, nb_repetition = 3):\n",
    "    out = \"\"\n",
    "    last = ''\n",
    "    count = 0\n",
    "    for c in text:\n",
    "        if c == last:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = min(count, nb_repetition)\n",
    "            for i in range(min(count, nb_repetition)):\n",
    "                out += last\n",
    "            last = c\n",
    "            count = 1\n",
    "    for i in range(min(count, nb_repetition)):\n",
    "                out += last\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d64740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of text\n",
    "def clean_data(data):\n",
    "    for i in range(len(data)):\n",
    "        # Remove capital letters \n",
    "        data[i] = data[i].lower()\n",
    "        \n",
    "        # Remove links\n",
    "        data[i] = re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+','',data[i])\n",
    "        \n",
    "        # Replace @some_user to simply @ (ignore name of user but keep fact that used an @)\n",
    "        data[i] = re.sub('@(\\S)*', '@', data[i])\n",
    "        \n",
    "        #Remove repetition of characters\n",
    "        data[i] = remove_repetitions(data[i])\n",
    "        \n",
    "        #Consider \"...\" as useful word\n",
    "        data[i] = re.sub('\\.{3}', ' threedots ', data[i])\n",
    "        \n",
    "        #Remove apostrophe \n",
    "        data[i] = re.sub('\\'', '', data[i])\n",
    "                \n",
    "        #Remove sequences like \"&quot;\" and characters aside from letters (without accents) aside from \"@\"\n",
    "        data[i] = re.sub('&.*;|[^a-zA-z@\\s]', '', data[i])\n",
    "        \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfec136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change textual label to int\n",
    "# 0: negative ; 1: neutral ; 2: positive\n",
    "def label_to_int(labels):\n",
    "    labels_int = np.zeros(labels.shape,dtype='int')\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == 'neutral':\n",
    "            labels_int[i] = 1\n",
    "        elif labels[i] == 'positive':\n",
    "            labels_int[i] = 2\n",
    "    return labels_int\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c42a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls nltk's tokenizer on array of entries\n",
    "def tokenize(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = np.array(nltk.tokenize.word_tokenize(data[i]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0104f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls nltk's lemmatizer on array of entries already lemmatized\n",
    "def lemmatize(data):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            data[i][j] = lemmatizer.lemmatize(data[i][j])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e66f9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://www.jmlr.org/papers/volume2/lodhi02a/lodhi02a.pdf\n",
    "# Decay is a hyperparameter between 0 and 1 controlling decay when sequences are far in the text\n",
    "# When decay = 1, \"cat\" and \"cut\" would have the same score as \"cat\" and \"ct\"\n",
    "# \"n\" specifies the size of subsequences to consider (not the max size, but the exact size)\n",
    "def string_subsequence_kernel(sequence1, sequence2, decay=0.03, n=5):\n",
    "    \n",
    "    # Define s and t, the strings to compare\n",
    "    s = sequence1\n",
    "    t = sequence2\n",
    "    \n",
    "    # dynamic programming matrix for K'' (see article for details)\n",
    "    # used to reduce computation cost of O(n|s||t|^2) to O(n|s||t|) (do not iterate again on |t|)\n",
    "    m2 = np.empty((len(t)+1, n+1, len(s)+1))            \n",
    "    \n",
    "    # dynamic programming matrix with m[i][j][k] containing K'_j(s[0:k+1], t[0:i+1])\n",
    "    # aside for when j = n, then it contains K_n instead of K'_n\n",
    "    # cell m[len(t)][n][len(s)] contain the desired value\n",
    "    # (see article for details)\n",
    "    m = np.empty((len(t)+1, n+1,len(s)+1))\n",
    "    \n",
    "    # Iterate over length of t to consider\n",
    "    for i in range(len(t)+1):\n",
    "        # Iterate over n (lengh of sequence)\n",
    "        for j in range(n+1):\n",
    "            # Iterate over length of s to consider\n",
    "            for k in range(len(s)+1):\n",
    "                \n",
    "                # n = 0, give score of 1\n",
    "                if j == 0:\n",
    "                    m[i][j][k] = 1\n",
    "                    m2[i][j][k] = 1\n",
    "                \n",
    "                # one string is too short compared to n, score of 0\n",
    "                elif k < j or i < j:\n",
    "                    m[i][j][k] = 0\n",
    "                    m2[i][j][k] = 0\n",
    "                    \n",
    "                # last row, compute K_n\n",
    "                elif j == n:\n",
    "                    # Add score for s[:-1] for current s length\n",
    "                    m[i][j][k] = m[i][j][k-1]\n",
    "                    \n",
    "                    # Find subsequences in t that match character s[-1] for current s length\n",
    "                    char = s[k-1]\n",
    "                    \n",
    "                    # Iterate over chars of t \n",
    "                    for l in range(i):\n",
    "                        if t[l] == char:\n",
    "                            m[i][j][k] += m[l][j-1][k-1] * decay**2\n",
    "                            \n",
    "                # compute K'_n\n",
    "                else :\n",
    "                    # Add score for s[:-1] for current s length\n",
    "                    m[i][j][k] = decay * m[i][j][k-1]\n",
    "                    \n",
    "                    # Find subsequences in t that match character s[-1] for current s length\n",
    "                    char = s[k-1]\n",
    "                    \n",
    "                    # Use optimization\n",
    "                    if char == t[i-1]:\n",
    "                        m2[i][j][k] = decay*(m2[i-1][j][k] + decay * m[i-1][j-1][k-1])                                                \n",
    "                        \n",
    "                    else :\n",
    "                        m2[i][j][k] = decay*m2[i-1][j][k]\n",
    "                    \n",
    "                    m[i][j][k] += m2[i][j][k]\n",
    "                    \n",
    "                    # Without optimization:\n",
    "                    \n",
    "                    # Iterate over chars of t \n",
    "                    #for l in range(i):\n",
    "                    #    if t[l] == char:\n",
    "                    #        m[i][j][k] += m[l][j-1][k-1] * decay**(i - l + 1) # note that the paper uses indexes from 0 \n",
    "                                \n",
    "                #print(i,\"   \",j, \"   \",k, \"   \", m[i][j][k])\n",
    "                                \n",
    "    return m[len(t)][n][len(s)]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c5cf3480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the value from string_subsequence_kernel\n",
    "# If the kernel is precomputed, this function is not used to avoid recomputing the denominator for each value \n",
    "# Useful if we want to pass a callable to the SVM\n",
    "def kernel_matrix_value(sequence1, sequence2, decay=0.03, n=5):\n",
    "    return string_subsequence_kernel(sequence1, sequence2, decay, n)/np.sqrt(string_subsequence_kernel(sequence1, sequence1, decay, n)*string_subsequence_kernel(sequence2, sequence2, decay, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16d5fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful when too many data for kernel\n",
    "# We could make batches to construct multiple smaller classifiers and have them vote\n",
    "def divide_data(data, nb_batches):\n",
    "    nb_entries = len(data)\n",
    "    batch_size = nb_entries/nb_batches\n",
    "    print(\"Received \", nb_entries, \" entries, dividing into batches of around \", batch_size, \" entries\")\n",
    "    \n",
    "    batches = np.empty(int(nb_batches),dtype=object)\n",
    "    \n",
    "    current_pointer = 0\n",
    "    for i in range(nb_batches):\n",
    "        if i == nb_batches-1:\n",
    "            batches[i] = data[current_pointer:]\n",
    "        else:\n",
    "            batch_size = int(np.round(float(nb_entries)/(nb_batches-i)))\n",
    "            batches[i] = data[current_pointer:(current_pointer + batch_size)]\n",
    "            nb_entries -= batch_size\n",
    "            current_pointer += batch_size\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4baf7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join array of text to single string\n",
    "# Used after tokenization and lemmatization since string_subsequence_kernel works on strings and not array of words\n",
    "def joint_data(data):\n",
    "    for i in range(len(data)):\n",
    "        data[i] = ' '.join(data[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ea593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "#                                                                                                   #\n",
    "#    Run this section if you DON'T already have train_data_cleaned.csv and test_data_cleaned.csv    #\n",
    "#                                                                                                   #\n",
    "#####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4931d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "train_label = pd.read_csv('train_results.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Preprocessing\n",
    "# Drop index\n",
    "train_data = train_data.values[:, -1]\n",
    "test_data = test_data.values[:, -1]\n",
    "train_label = train_label.values[: ,-1]\n",
    "\n",
    "# Labels as int (0: negative; 1: neutral; 2: positive)\n",
    "train_label = label_to_int(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d682098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "train_data = clean_data(train_data)\n",
    "test_data = clean_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d8feac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "train_data = tokenize(train_data)\n",
    "test_data = tokenize(test_data)\n",
    "\n",
    "# Lemmatize\n",
    "train_data = lemmatize(train_data)\n",
    "test_data = lemmatize(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "511cfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = joint_data(train_data)\n",
    "test_data = joint_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8dd42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once to produce train_data_cleaned.csv\n",
    "# Next time, simply load those files\n",
    "df = pd.DataFrame({'id': np.arange(len(train_data)),\n",
    "                      'text': train_data})\n",
    "df.to_csv('train_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "649cb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once to produce test_data_cleaned.csv\n",
    "# Next time, simply load those files\n",
    "df = pd.DataFrame({'id': np.arange(len(test_data)),\n",
    "                      'text': test_data})\n",
    "df.to_csv('test_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3805af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "#                                                                                         #\n",
    "#    Run this section if ALREADY have train_data_cleaned.csv and test_data_cleaned.csv    #\n",
    "#                                                                                         #\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('train_data_cleaned.csv')\n",
    "train_label = pd.read_csv('train_results.csv')\n",
    "test_data = pd.read_csv('test_data_cleaned.csv')\n",
    "\n",
    "# Preprocessing\n",
    "# Drop index\n",
    "train_data = train_data.values[:, -1]\n",
    "test_data = test_data.values[:, -1]\n",
    "train_label = train_label.values[: ,-1]\n",
    "\n",
    "# Labels as int (0: negative; 1: neutral; 2: positive)\n",
    "train_label = label_to_int(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#                                                                          #\n",
    "#    Run following sections after you ran one of the precedent sections    # \n",
    "#                                                                          #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd5eea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(train_data, train_label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "30a0d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use when computing the kernel for one dataset, during training\n",
    "# More efficient than the computation of the kernel for test\n",
    "def compute_kernel(data, decay = 0.03, n = 5):\n",
    "    kernel = np.empty((len(data), len(data)))\n",
    "    print(\"Computing kernel of \", len(data)**2, \"entries\")\n",
    "    \n",
    "    # Reusable values used in the denominator\n",
    "    ssk = np.empty(len(data))\n",
    "    for i in range(len(data)):\n",
    "        ssk[i] = string_subsequence_kernel(data[i], data[i], decay, n)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            if i == j:\n",
    "                kernel[i][j] = 1\n",
    "            elif i > j:\n",
    "                kernel[i][j] = kernel[j][i]\n",
    "            else:\n",
    "                kernel[i][j] = string_subsequence_kernel(data[i], data[j], decay, n)/np.sqrt(ssk[i]*ssk[j])\n",
    "            count += 1\n",
    "            if count % 1000 == 0:\n",
    "                print(\"Computed \", count, \"entries\")\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f24402a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use when computing the kernel between two datasets, during testing\n",
    "def compute_kernel_test(train, test, decay = 0.03, n = 5):\n",
    "    kernel = np.empty((len(train), len(test)))\n",
    "    print(\"Computing kernel of \", len(train)*len(test), \"entries\")\n",
    "    \n",
    "    ssk_train = np.empty(len(train))\n",
    "    for i in range(len(train)):\n",
    "        ssk_train[i] = string_subsequence_kernel(train[i], train[i], decay, n)\n",
    "    ssk_test = np.empty(len(test))\n",
    "    for i in range(len(test)):\n",
    "        ssk_test[i] = string_subsequence_kernel(test[i], test[i], decay, n)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(train)):\n",
    "        for j in range(len(test)):            \n",
    "            kernel[i][j] = string_subsequence_kernel(train[i], test[j], decay, n)/np.sqrt(ssk_train[i]*ssk_test[j])\n",
    "            count += 1\n",
    "            if count % 1000 == 0:\n",
    "                print(\"Computed \", count, \"entries\")\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "23c212c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to test implementation, not called\n",
    "def compute_self_ssk(data, decay=0.03, n=5):\n",
    "    ssk = np.empty(len(data))\n",
    "    for i in range(len(data)):\n",
    "        ssk[i] = string_subsequence_kernel(data[i], data[i], decay, n)\n",
    "    return ssk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a5ae2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters :\n",
    "kernel_decay = 0.03\n",
    "kernel_n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "638c0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received  1040323  entries, dividing into batches of around  346.77433333333335  enties\n",
      "Received  560175  entries, dividing into batches of around  560.175  enties\n"
     ]
    }
   ],
   "source": [
    "train_batches = divide_data(train_data,3000) \n",
    "test_batches = divide_data(test_data,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "584f5ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing kernel of  120409 entries\n",
      "Computed  1000 entries\n",
      "Computed  2000 entries\n",
      "Computed  3000 entries\n",
      "Computed  4000 entries\n",
      "Computed  5000 entries\n",
      "Computed  6000 entries\n",
      "Computed  7000 entries\n",
      "Computed  8000 entries\n",
      "Computed  9000 entries\n",
      "Computed  10000 entries\n",
      "Computed  11000 entries\n",
      "Computed  12000 entries\n",
      "Computed  13000 entries\n",
      "Computed  14000 entries\n",
      "Computed  15000 entries\n",
      "Computed  16000 entries\n",
      "Computed  17000 entries\n",
      "Computed  18000 entries\n",
      "Computed  19000 entries\n",
      "Computed  20000 entries\n",
      "Computed  21000 entries\n",
      "Computed  22000 entries\n",
      "Computed  23000 entries\n",
      "Computed  24000 entries\n",
      "Computed  25000 entries\n",
      "Computed  26000 entries\n",
      "Computed  27000 entries\n",
      "Computed  28000 entries\n",
      "Computed  29000 entries\n",
      "Computed  30000 entries\n",
      "Computed  31000 entries\n",
      "Computed  32000 entries\n",
      "Computed  33000 entries\n",
      "Computed  34000 entries\n",
      "Computed  35000 entries\n",
      "Computed  36000 entries\n",
      "Computed  37000 entries\n",
      "Computed  38000 entries\n",
      "Computed  39000 entries\n",
      "Computed  40000 entries\n",
      "Computed  41000 entries\n",
      "Computed  42000 entries\n",
      "Computed  43000 entries\n",
      "Computed  44000 entries\n",
      "Computed  45000 entries\n",
      "Computed  46000 entries\n",
      "Computed  47000 entries\n",
      "Computed  48000 entries\n",
      "Computed  49000 entries\n",
      "Computed  50000 entries\n",
      "Computed  51000 entries\n",
      "Computed  52000 entries\n",
      "Computed  53000 entries\n",
      "Computed  54000 entries\n",
      "Computed  55000 entries\n",
      "Computed  56000 entries\n",
      "Computed  57000 entries\n",
      "Computed  58000 entries\n",
      "Computed  59000 entries\n",
      "Computed  60000 entries\n",
      "Computed  61000 entries\n",
      "Computed  62000 entries\n",
      "Computed  63000 entries\n",
      "Computed  64000 entries\n",
      "Computed  65000 entries\n",
      "Computed  66000 entries\n",
      "Computed  67000 entries\n",
      "Computed  68000 entries\n",
      "Computed  69000 entries\n",
      "Computed  70000 entries\n",
      "Computed  71000 entries\n",
      "Computed  72000 entries\n",
      "Computed  73000 entries\n",
      "Computed  74000 entries\n",
      "Computed  75000 entries\n",
      "Computed  76000 entries\n",
      "Computed  77000 entries\n",
      "Computed  78000 entries\n",
      "Computed  79000 entries\n",
      "Computed  80000 entries\n",
      "Computed  81000 entries\n",
      "Computed  82000 entries\n",
      "Computed  83000 entries\n",
      "Computed  84000 entries\n",
      "Computed  85000 entries\n",
      "Computed  86000 entries\n",
      "Computed  87000 entries\n",
      "Computed  88000 entries\n",
      "Computed  89000 entries\n",
      "Computed  90000 entries\n",
      "Computed  91000 entries\n",
      "Computed  92000 entries\n",
      "Computed  93000 entries\n",
      "Computed  94000 entries\n",
      "Computed  95000 entries\n",
      "Computed  96000 entries\n",
      "Computed  97000 entries\n",
      "Computed  98000 entries\n",
      "Computed  99000 entries\n",
      "Computed  100000 entries\n",
      "Computed  101000 entries\n",
      "Computed  102000 entries\n",
      "Computed  103000 entries\n",
      "Computed  104000 entries\n",
      "Computed  105000 entries\n",
      "Computed  106000 entries\n",
      "Computed  107000 entries\n",
      "Computed  108000 entries\n",
      "Computed  109000 entries\n",
      "Computed  110000 entries\n",
      "Computed  111000 entries\n",
      "Computed  112000 entries\n",
      "Computed  113000 entries\n",
      "Computed  114000 entries\n",
      "Computed  115000 entries\n",
      "Computed  116000 entries\n",
      "Computed  117000 entries\n",
      "Computed  118000 entries\n",
      "Computed  119000 entries\n",
      "Computed  120000 entries\n"
     ]
    }
   ],
   "source": [
    "# Computed only for the first batch of 347 entries, due to lack of time\n",
    "kernel = compute_kernel(train_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d6a1eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once to save computation of the first kernel\n",
    "np.savetxt(\"kernel1.csv\",kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6caa5aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing kernel of  34353 entries\n",
      "Computed  1000 entries\n",
      "Computed  2000 entries\n",
      "Computed  3000 entries\n",
      "Computed  4000 entries\n",
      "Computed  5000 entries\n",
      "Computed  6000 entries\n",
      "Computed  7000 entries\n",
      "Computed  8000 entries\n",
      "Computed  9000 entries\n",
      "Computed  10000 entries\n",
      "Computed  11000 entries\n",
      "Computed  12000 entries\n",
      "Computed  13000 entries\n",
      "Computed  14000 entries\n",
      "Computed  15000 entries\n",
      "Computed  16000 entries\n",
      "Computed  17000 entries\n",
      "Computed  18000 entries\n",
      "Computed  19000 entries\n",
      "Computed  20000 entries\n",
      "Computed  21000 entries\n",
      "Computed  22000 entries\n",
      "Computed  23000 entries\n",
      "Computed  24000 entries\n",
      "Computed  25000 entries\n",
      "Computed  26000 entries\n",
      "Computed  27000 entries\n",
      "Computed  28000 entries\n",
      "Computed  29000 entries\n",
      "Computed  30000 entries\n",
      "Computed  31000 entries\n",
      "Computed  32000 entries\n",
      "Computed  33000 entries\n",
      "Computed  34000 entries\n"
     ]
    }
   ],
   "source": [
    "# Test with some values \n",
    "predictions = np.empty(0)\n",
    "\n",
    "svc = SVC(kernel='precomputed')\n",
    "\n",
    "kernel_train = kernel\n",
    "\n",
    "svc.fit(kernel_train, y_train[0:len(train_batches[0])])\n",
    "\n",
    "# Would be useful if we had trained more kernels\n",
    "votes = np.zeros((99,3))\n",
    "\n",
    "# 99 test samples, the 99 last entries of train_data\n",
    "kernel_test = compute_kernel_test(train_data[-100:-1], train_batches[0])\n",
    "\n",
    "y_pred = svc.predict(kernel_test)\n",
    "\n",
    "# Would be useful if we had trained more kernels\n",
    "for k in range(len(y_pred)):\n",
    "    votes[k][int(y_pred[k])] += 1\n",
    "    \n",
    "for k in range(len(votes)):\n",
    "    predictions = np.append(predictions, np.argmax(votes[k]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "543028aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 2., 0., 2., 0., 0., 2., 0., 2., 0., 0., 2., 2., 0., 0.,\n",
       "       0., 0., 0., 0., 2., 2., 0., 0., 2., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
       "       0., 2., 0., 2., 2., 0., 0., 0., 0., 0., 2., 0., 0., 2., 0., 2., 0.,\n",
       "       0., 0., 2., 0., 2., 0., 0., 0., 2., 0., 0., 0., 2., 2., 0., 2., 0.,\n",
       "       2., 2., 0., 0., 2., 2., 0., 0., 0., 0., 0., 0., 2., 0., 0., 2., 2.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 2., 2., 0., 0., 0., 2.])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to verify that it \"seems\" to work\n",
    "predictions[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8047d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResults(predictions[0:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ac01c82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2,\n",
       "       0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2,\n",
       "       0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0,\n",
       "       2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with real entries\n",
    "y_train[-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "354e7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compte error rate\n",
    "def test(predictions, labels):\n",
    "        nb_errors = 0.0\n",
    "        for i in range(len(labels)):            \n",
    "            if predictions[i] != labels[i]:\n",
    "                nb_errors += 1.0\n",
    "                \n",
    "        return nb_errors/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0b526537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5252525252525253"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "test(predictions[0:99], y_train[-100:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715621c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "#                                                             #\n",
    "#   Code below this point were not used but could be useful   #\n",
    "#                                                             #\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72833664",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Computing kernel of  5824 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guomu\\AppData\\Local\\Temp/ipykernel_87760/2261394038.py:15: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  kernel[i][j] = string_subsequence_kernel(train[i], test[j], decay, n)/np.minimum(np.sqrt(ssk_train[i]*ssk_test[j]),1e-4)\n",
      "C:\\Users\\guomu\\AppData\\Local\\Temp/ipykernel_87760/2261394038.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  kernel[i][j] = string_subsequence_kernel(train[i], test[j], decay, n)/np.minimum(np.sqrt(ssk_train[i]*ssk_test[j]),1e-4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed  1000 entries\n",
      "Computed  2000 entries\n",
      "Computed  3000 entries\n",
      "Computed  4000 entries\n",
      "Computed  5000 entries\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_87760/2405128763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mkernel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_kernel_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mvotes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \"\"\"\n\u001b[1;32m--> 414\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             X = self._validate_data(\n\u001b[0m\u001b[0;32m    593\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#just 1 kernel\n",
    "predictions = np.empty(0)\n",
    "\n",
    "svc = SVC(kernel='precomputed')\n",
    "\n",
    "kernel_train = kernel\n",
    "\n",
    "svc.fit(kernel_train, y_train[0:len(train_batches[0])])\n",
    "\n",
    "# Calculate for some batches of test\n",
    "for i in range(10):\n",
    "    print(\"Batch\", i)\n",
    "    votes = np.zeros((len(test_batches[i]),3))\n",
    "    kernel_test = compute_kernel_test(test_batches[i], train_batches[0])\n",
    "        \n",
    "    y_pred = svc.predict(kernel_test)\n",
    "    for k in range(len(y_pred)):\n",
    "        votes[k][int(y_pred[k])] += 1\n",
    "    \n",
    "for k in range(len(votes)):\n",
    "    predictions = np.append(predictions, np.argmax(votes[k]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ecfa9b3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing kernel of  2179115761 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guomu\\AppData\\Local\\Temp/ipykernel_87760/215594344.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return string_subsequence_kernel(sequence1, sequence2, decay, n)/np.sqrt(string_subsequence_kernel(sequence1, sequence1, decay, n)*string_subsequence_kernel(sequence2, sequence2, decay, n))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_87760/3650522034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvotes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mkernel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculations for batch train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\", and test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_87760/1998197179.py\u001b[0m in \u001b[0;36mcompute_kernel\u001b[1;34m(data, decay, n)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mkernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel_matrix_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_87760/215594344.py\u001b[0m in \u001b[0;36mkernel_matrix_value\u001b[1;34m(sequence1, sequence2, decay, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Normalizes the value from string_subsequence_kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mkernel_matrix_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstring_subsequence_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring_subsequence_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstring_subsequence_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_87760/325557993.py\u001b[0m in \u001b[0;36mstring_subsequence_kernel\u001b[1;34m(sequence1, sequence2, decay, n)\u001b[0m\n\u001b[0;32m     40\u001b[0m                     \u001b[1;31m# Iterate over chars of t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                         \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mchar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                             \u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;31m# compute K'_n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For all\n",
    "# Would take to long to run unfortunately\n",
    "counter_train = 0\n",
    "predictions = np.empty(0)\n",
    "for i in range(len(test_batches)):\n",
    "    votes = np.zeros((len(test_batches[i]),3))\n",
    "    kernel_test = compute_kernel(test_batches[i])\n",
    "    for j in range(len(train_batches)):\n",
    "        print(\"Calculations for batch train \", j, \", and test \", i)\n",
    "        kernel_train = compute_kernel(train_batches[j])\n",
    "        svc = SVC(kernel='precomputed')\n",
    "        \n",
    "        svc.fit(kernel_train, y_train[counter_train:(counter_train + len(train_batches[j]))])\n",
    "        counter_train += len(train_batches[j])\n",
    "        y_pred = svc.predict(kernel_test)\n",
    "        for k in range(len(y_pred)):\n",
    "            votes[k][int(y_pred[k])] += 1\n",
    "    \n",
    "for k in range(len(votes)):\n",
    "    predictions = np.append(predictions, np.argmax(votes[k]))       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58fcc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the results as predictions.csv\n",
    "def saveResults(predictions):\n",
    "    df = pd.DataFrame({'id': np.arange(len(predictions)),\n",
    "                      'target': predictions})\n",
    "    df.astype(int).to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65658d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#                                                                                                 #\n",
    "#    Below are some old code that were used to find best hyperparameter for logistic regression   #\n",
    "#    Remove for final submission                                                                  #\n",
    "#                                                                                                 #\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for each hyperparameter\n",
    "#errors = np.empty(len(FIRST_HYPERPARAMETER))\n",
    "#print(\"Training for SVM\")\n",
    "#for i in range(len()):\n",
    "#    val = regularization_terms[i]\n",
    "#    print(\"Current hyperparameter value :\", str(val))\n",
    "#    logistic_regression = Logistic_Regression(np.zeros((nb_features + 1, NB_CLASSES)), reg, np.arange(NB_CLASSES))\n",
    "#    logistic_regression.train(x_train, y_train, initial_step=initial_step, max_steps=step_number, plt=False)\n",
    "#    errors[i] = logistic_regression.test(x_validation, y_validation)\n",
    "\n",
    "# Choose best hyperparameter\n",
    "#index_min = np.argmin(errors)\n",
    "#best_hyperparam = ARRAY_OF_HYPERPARAM[index_min]\n",
    "#print(\"Best value for hyperparameter : \", str(best_hyperparam))\n",
    "#print(\"Error on validation for best hyperparameter\", str(errors[index_min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfae64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for all hyperparameters\n",
    "#print(\"Values tested :\", regularization_terms)\n",
    "#print(\"Error rates :\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and obtain predictions for best hyperparameter\n",
    "#logistic_regression = Logistic_Regression(np.zeros((nb_features + 1, NB_CLASSES)), best_lambda, np.arange(NB_CLASSES))\n",
    "#l,e = logistic_regression.train(np.concatenate((x_train, x_validation)), np.concatenate((y_train, y_validation)), initial_step=initial_step, max_steps=step_number, plt=False)\n",
    "#pred = logistic_regression.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results of predictions on test data\n",
    "#saveResults(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
